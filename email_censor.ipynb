{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we have four emails that need to be censered.\n",
    "\n",
    "using The open() function is opening the text file that the emails are contained in and the \n",
    ".read() method is allowing us to save their contexts to the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "email_one = open(\"email_one.txt\", \"r\").read()\n",
    "email_two = open(\"email_two.txt\", \"r\").read()\n",
    "email_three = open(\"email_three.txt\", \"r\").read()\n",
    "email_four = open(\"email_four.txt\", \"r\").read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that can censor a specific word or phrase from a body of text, and then return the text.\n",
    "we have been asked to use the function to censor all instances of the phrase \"learning algorithms\" from the first email, email_one.the Manager doesn’t care how we censor it, he just wants it done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censor_one(input_text, censor):\n",
    "  censored_item = \"\"\n",
    "  for x in range(0,len(censor)):\n",
    "    if censor[x] == \" \":\n",
    "      censored_item = censored_item + \" \"\n",
    "    else:\n",
    "    \tcensored_item = censored_item + \"X\"\n",
    "  return input_text.replace(censor, censored_item)\n",
    "\n",
    "#print(censor_one(email_one, \"learning algorithm\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that can censor not just a specific word or phrase from a body of text, but a whole list of words and phrases, and then return the text.\n",
    "\n",
    "from email_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proprietary_terms = [\"she\", \"personality matrix\", \"sense of self\", \"self-preservation\", \"learning algorithm\", \"her\", \"herself\", \"Helena\"]\n",
    "\n",
    "def censor_two(input_text, censored_list):\n",
    "  for word in censored_list:\n",
    "    censored_word = \"\"\n",
    "    for x in range(0,len(word)):\n",
    "      if word[x] == \" \":\n",
    "        censored_word = censored_word + \" \"\n",
    "      else:\n",
    "        censored_word = censored_word + \"X\"\n",
    "    input_text = input_text.replace(word, censored_word)\n",
    "  return input_text\n",
    "#print(censor_two(email_two, proprietary_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that can censor any occurance of a word from the “negative words” list after any “negative” word has occurred twice, as well as censoring everything from the list from the previous step as well and use it to censor email_three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = [\"concerned\", \"behind\", \"danger\", \"dangerous\", \"alarming\", \"alarmed\", \"out of control\", \"help\", \"unhappy\", \"bad\", \"upset\", \"awful\", \"broken\", \"damage\", \"damaging\", \"dismal\", \"distressed\", \"distressed\", \"concerning\", \"horrible\", \"horribly\", \"questionable\"]\n",
    "\n",
    "def censor_three(input_text, censored_list, negative_words):\n",
    "  input_text_words = []\n",
    "  for x in input_text.split(\" \"):\n",
    "    x1 = x.split(\"\\n\")\n",
    "    for word in x1:\n",
    "      input_text_words.append(word)\n",
    "  for i in range(0,len(input_text_words)):\n",
    "    if (input_text_words[i] in censored_list) == True:\n",
    "      word_clean = input_text_words[i]\n",
    "      censored_word = \"\"\n",
    "      for x in range(0,len(word_clean)):\n",
    "        censored_word = censored_word + \"X\"\n",
    "      input_text_words[i] = input_text_words[i].replace(word_clean, censored_word)\n",
    "    count = 0\n",
    "    for i in range(0,len(input_text_words)):\n",
    "      if (input_text_words[i] in negative_words) == True:\n",
    "        count += 1\n",
    "        if count > 2:\n",
    "          word_clean = input_text_words[i]\n",
    "          for x in punctuation:\n",
    "            word_clean = word_clean.strip(x)\n",
    "          censored_word = \"\"\n",
    "          for x in range(0,len(word_clean)):\n",
    "            censored_word = censored_word + \"X\"\n",
    "          input_text_words[i] = input_text_words[i].replace(word_clean, censored_word)\n",
    "  return \" \".join(input_text_words)\n",
    "\n",
    "# print(censor_three(email_three, proprietary_terms, negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)",
   "language": "python",
   "name": "python361064bitpythondataconda78ac61cb7ad5453197bfca4731d0b634"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
